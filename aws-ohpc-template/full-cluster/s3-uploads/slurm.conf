# SLURM configuration file

ClusterName=aws-openhpc
ControlMachine=@HEADNODE@
ControlAddr=@IP@

SlurmdUser=root
SlurmctldPort=6817
SlurmdPort=6818
AuthType=auth/munge
StateSaveLocation=/var/spool/slurm/ctld
SlurmdSpoolDir=/var/spool/slurm/d
MpiDefault=none
SlurmctldPidFile=/var/run/slurmctld.pid
SlurmdPidFile=/var/run/slurmd.pid
ProctrackType=proctrack/pgid

# TIMERS
SlurmctldTimeout=300
SlurmdTimeout=60
InactiveLimit=0
MinJobAge=300
KillWait=30
Waittime=0

# SCHEDULING
SchedulerType=sched/hold
SelectType=select/linear

# PLACEMENT
TopologyPlugin=topology/tree

# LOGGING
SlurmctldDebug=3
SlurmctldLogFile=/var/log/slurmctld.log
SlurmdDebug=3
SlurmdLogFile=/var/log/slurmd.log
DebugFlags=NO_CONF_HASH
JobCompType=jobcomp/none

# SCALING
CommunicationParameters=NoAddrCache
SlurmctldParameters=idle_on_node_suspend
SuspendTime=300
SuspendTimeout=60
ResumeTimeout=600
TreeWidth=65533
SuspendProgram=/cluster/slurm/bin/slurm-aws-shutdown.sh
ResumeProgram=/cluster/slurm/bin/slurm-aws-startup.sh
ResumeFailProgram=/cluster/slurm/bin/slurm-aws-shutdown.sh
TCPTimeout=5
ResumeRate=1200
SuspendRate=1200

# COMPUTE NODES
NodeName=o[000-499]z[1-3] CPUs=48 State=Cloud
NodeName=s[000-499]z[1-3] CPUs=48 State=Cloud
NodeName=m[000-199]z[1-3] CPUs=36 State=Cloud
# PARTITIONS
PartitionName=openfoam.c5.24xl Nodes=o[000-499]z[1-3] Default=NO MaxTime=48:00:00 State=UP
PartitionName=starccm.c5.24xl Nodes=s[000-499]z[1-3] Default=YES MaxTime=48:00:00 State=UP
PartitionName=starccm.c5n.18xl Nodes=m[000-199]z[1-3] Default=NO MaxTime=48:00:00 State=UP
